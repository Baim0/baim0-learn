## 5.通过Logstash过滤、分析日志数据

## 1.Logstash日志收集与分析系统

## 1.1 下载与安装Logstash

Logstash需要安装Java运行环境，这在前面章节已经介绍过了，这里不再介绍，读者可以从elastic官网https://www.elastic.co/downloads/logstash 获取logstash安装包，这里下载的版本是logstash-6.3.2.tar.gz。将下载下来的安装包直接解压到一个路径下即可完成logstash的安装。根据前面的规划，将logstash安装到logstashserver主机（172.16.213.120）上，这里统一将logstash安装到/usr/local目录下，基本操作过程如下：

```coffeescript
[root@logstashserver ~]# tar -zxvf logstash-6.3.2.tar.gz -C /usr/local
[root@logstashserver ~]# mv /usr/local/logstash-6.3.2 /usr/local/logstash
```

这里我们将logstash安装到了/usr/local目录下。

## 1.2 Logstash是怎么工作的

Logstash是一个开源的、服务端的数据处理pipeline（管道），它可以接收多个源的数据、然后对它们进行转换、最终将它们发送到指定类型的目的地。Logstash是通过插件机制实现各种功能的，读者可以在https://github.com/logstash-plugins 下载各种功能的插件，也可以自行编写插件。

Logstash实现的功能主要分为接收数据、解析过滤并转换数据、输出数据三个部分，对应的插件依次是input插件、filter插件、output插件，其中，filter插件是可选的，其它两个是必须插件。也就是说在一个完整的Logstash配置文件中，必须有input插件和output插件。

## 1.3 常用的input

input插件主要用于接收数据，Logstash支持接收多种数据源，常用的有如下几种：

> \-file:读取一个文件，这个读取功能有点类似于linux下面的tail命令，一行一行的实时读取。  
> \-syslog: 监听系统514端口的syslog messages，并使用RFC3164格式进行解析。  
> \-redis: Logstash可以从redis服务器读取数据，此时redis类似于一个消息缓存组件。  
> \-kafka：Logstash也可以从kafka集群中读取数据，kafka加Logstash的架构一般用在数据量较大的业务场景，kafka可用作数据的缓冲和存储。  
> \-filebeat：filebeat是一个文本日志收集器，性能稳定，并且占用系统资源很少，Logstash可以接收filebeat发送过来的数据。

## 1.4 常用的filter

filter插件主要用于数据的过滤、解析和格式化，也就是将非结构化的数据解析成结构化的、可查询的标准化数据。常见的filter插件有如下几个：

> \-grok：grok是Logstash最重要的插件，可解析并结构化任意数据，支持正则表达式，并提供了很多内置的规则和模板可供使用。此插件使用最多，但也最复杂。  
> \-mutate：此插件提供了丰富的基础类型数据处理能力。包括类型转换，字符串处理和字段处理等。  
> \-date：此插件可以用来转换你的日志记录中的时间字符串。  
> \-GeoIP：此插件可以根据IP地址提供对应的地域信息，包括国别，省市，经纬度等，对于可视化地图和区域统计非常有用。

## 1.5 常用的output

output插件用于数据的输出，一个Logstash事件可以穿过多个output，直到所有的output处理完毕，这个事件才算结束。输出插件常见的有如下几种：

> \-elasticsearch：发送数据到elasticsearch。  
> \-file：发送数据到文件中。  
> \-redis：发送数据到redis中，从这里可以看出，redis插件既可以用在input插件中，也可以用在output插件中。  
> \-kafka：发送数据到kafka中，与redis插件类似，此插件也可以用在Logstash的输入和输出插件中。

## 1.6 Logstash配置文件入门

这里我们将logstash安装到/usr/local目录下，因此，logstash的配置文件目录为/usr/local/logstash/config/，其中，jvm.options是设置JVM内存资源的配置文件，logstash.yml是logstash全局属性配置文件，一般无需修改，另外还需要自己创建一个logstash事件配置文件，这里重点介绍下logstash事件配置文件的编写方法和使用方式。

在介绍Logstash配置之前，先来认识一下logstash是如何实现输入和输出的。

Logstash提供了一个shell脚本/usr/local/logstash/bin/logstash,可以方便快速的启动一个logstash进程，在Linux命令行下，运行如下命令启动Logstash进程：

```coffeescript
[root@logstashserver ~]# cd /usr/local/logstash/
[root@logstashserver logstash]# bin/logstash -e 'input{stdin{}} output{stdout{codec=>rubydebug}}'
```

首先解释下这条命令的含义：

> \-e代表执行的意思。  
> input即输入的意思，input里面即是输入的方式，这里选择了stdin，就是标准输入（从终端输入）。  
> output即输出的意思，output里面是输出的方式，这里选择了stdout，就是标准输出（输出到终端）。  
> 这里的codec是个插件，表明格式。这里放在stdout中，表示输出的格式，rubydebug是专门用来做测试的格式，一般用来在终端输出JSON格式。

接着，在终端输入信息。这里我们输入"Hello World"，按回车，马上就会有返回结果，内容如下：

```php
{
"@version" => "1",
"host" => "logstashserver",
"@timestamp" => 2018-07-26T10:01:45.665Z,
"message" => "Hello World"
}
```

这就是logstash的输出格式。Logstash在输出内容中会给事件添加一些额外信息。比如"@version"、"host"、"@timestamp"都是新增的字段，而最重要的是@timestamp，用来标记事件的发生时间。由于这个字段涉及到Logstash内部流转，如果给一个字符串字段重命名为@timestamp的话，Logstash就会直接报错。另外，也不能删除这个字段。

在logstash的输出中，常见的字段还有type，表示事件的唯一类型、tags，表示事件的某方面属性，我们可以随意给事件添加字段或者从事件里删除字段。

在执行上面的命令后，可以看到，我们输入什么内容，logstash就会按照上面的格式输出什么内容。使用CTRL-C命令可以退出运行的Logstash事件。

使用-e参数在命令行中指定配置是很常用的方式，但是如果logstash需要配置更多规则的话，就必须把配置固化到文件里，这就是logstash事件配置文件，如果把上面在命令行执行的logstash命令，写到一个配置文件logstash-simple.conf中，就变成如下内容：

```plain
input { 
stdin { }
}
output {
stdout { codec => rubydebug }
}
```

这就是最简单的Logstash事件配置文件。此时，可以使用logstash的-f参数来读取配置文件，然后启动logstash进程，操作如下：

```coffeescript
[root@logstashserver logstash]# bin/logstash -f logstash-simple.conf
```

通过这种方式也可以启动logstash进程，不过这种方式启动的进程是在前台运行的，要放到后台运行，可通过nohup命令实现，操作如下：

```coffeescript
[root@logstashserver logstash]# nohup bin/logstash -f logstash-simple.conf &
```

这样，logstash进程就放到了后台运行了，在当前目录会生成一个nohup.out文件，可通过此文件查看logstash进程的启动状态。

## 1.7 logstash事件文件配置实例

下面再看另一个logstash事件配置文件，内容如下：

```makefile
input {

file {
path => "/var/log/messages"
}
}
output {
stdout {
codec => rubydebug
}
}
```

首先看input插件，这里定义了input的输入源为file，然后指定了文件的路径为/var/log/messages，也就是将此文件的内容作为输入源，这里的path属性是必填配置，后面的路径必须是绝对路径，不能是相对路径。如果需要监控多个文件，可以通过逗号分隔即可，例如：

```plain
path => ["/var/log/*.log","/var/log/message","/var/log/secure"]
```

对于output插件，这里仍然采用rubydebug的JSON输出格式，这对于调试logstash输出信息是否正常非常有用。

将上面的配置文件内容保存为logstash\_in\_stdout.conf，然后启动一个logstash进程，执行如下命令：

```coffeescript
[root\@logstashserver logstash]# nohup bin/logstash -f logstash_in_stdout.conf &
```

接着开始进行输入、输出测试，这里设定/var/log/messages的输入内容为如下信息（其实就是执行“systemctl stop nginx”命令后/var/log/messages的输出内容）：

```css
Jan 29 16:09:12 logstashserver systemd: Stopping The nginx HTTP and reverse
proxy server...
Jan 29 16:09:12 logstashserver systemd: Stopped The nginx HTTP and reverse proxy
server.
```

然后查看logstash的输出信息，可以看到内容如下：

```php
{
"@version" => "1",
"host" => " logstashserver",
"path" => "/var/log/messages",
"@timestamp" => 2018-01-29T08:09:12.701Z,
"message" => "Jan 29 16:09:12 logstashserver systemd: Stopping The nginx HTTP
and reverse proxy server..."
}

{
"@version" => "1",
"host" => " logstashserver",
"path" => "/var/log/messages",
"@timestamp" => 2018-01-29T08:09:12.701Z,
"message" => "Jan 29 16:09:12 logstashserver systemd: Stopped The nginx HTTP
and reverse proxy server."
}
```

这就是json格式的输出内容，可以看到，输入的内容放到了"message"字段中保持原样输出了，并且还增加了四个字段，这四个字段是logstash自动添加上去的。

通过这个输出可知，上面的配置文件没有问题，数据可以正常输出，那么，接着我们把logstash\_in\_stdout.conf文件稍加修改，变成另外一个事件配置文件logstash\_in\_kafka.conf，内容如下：

```makefile
input {
file {
path => "/var/log/messages"
}
}

output {
kafka {
bootstrap_servers =>
"172.16.213.51:9092,172.16.213.75:9092,172.16.213.109:9092"
topic_id => "osmessages"
}
}
```

这个配置文件中，输入input仍然是file，重点看输出插件，这里定义了output的输出源为kafka，通过bootstrap\_servers选项指定了kafka集群的IP地址和端口。特别注意这里IP地址的写法，每个IP地址之间通过逗号分隔。另外，output输出中的topic\_id选项，是指定输出到kafka中的哪个topic下，这里是osmessages，如果无此topic，会自动重建topic。

此事件配置文件所表达的含义是：将系统中/var/log/messages文件的内容实时的同步到kafka集群名为osmessages的topic下。

下面将logstash\_in\_kafka.conf事件配置文件启动起来，启动方法，与上面相同，不再介绍，接着，在logstashserver节点的/var/log/messages中生成如下日志：

```coffeescript
[root@logstashserver logstash]# echo "Jan 29 18:23:06 logstashserver
sshd[15895]: Server listening on :: port 22." >> /var/log/messages
```

然后，选择任一个kafka集群节点，执行如下命令：

```coffeescript
[root@kafkazk3 kafka]# bin/kafka-console-consumer.sh --zookeeper 172.16.213.109:2181 --topic osmessages
2018-07-29T10:23:44.752Z logstashserver July 29 18:23:06 logstashserver sshd[15895]: Server listening on :: port 22.
```

这个命令就是在kafka端消费信息，可以看出，输入的信息在kafka消费端输出了，只不过在消息最前面增加了一个时间字段和一个主机字段。

## 1.8 配置logstash作为转发节点

上面对logstash的使用做了一个基础的介绍，现在回到本节介绍的这个案例中，在这个部署架构中，logstash是作为一个二级转发节点使用的，也就是它将kafka作为数据接收源，然后将数据发送到elasticsearch集群中，按照这个需求，新建logstash事件配置文件kafka\_os\_into\_es.conf，内容如下：

```makefile
input {
kafka {
bootstrap_servers =>
"172.16.213.51:9092,172.16.213.75:9092,172.16.213.109:9092"
topics => ["osmessages"]
codec => "json"
}
}

output {
elasticsearch {
hosts => ["172.16.213.37:9200","172.16.213.77:9200","172.16.213.78:9200"]
index => " osmessageslog-%{+YYYY-MM-dd}"
}
}
```

从配置文件可以看到，input接收源变成了kafka，通过bootstrap\_servers和topics两个选项指定了接收源kafka的属性信息，因为logstash从kafka获取到的数据内容为json格式，所以还需要在input字段加入codec=>json来进行解析，接着，output输出类型配置为elasticsearch，并通过hosts选项指定了elasticsearch集群的地址，最后通过index指定了索引的名称，也就是下面要用到的Index pattern。

logstash的事件配置文件这里暂时先介绍这么多，更多功能配置后面会做更深入介绍。

